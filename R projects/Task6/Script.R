library(MASS)
x1<-rnorm(10,6,2)
y1<-rnorm(10,6,2)
x2<-rnorm(20,0,2)
y2<-rnorm(20,0,2)
xy<-cbind(c(x1, x2),c(y1, y2))

t<-scale(xy)
t

cl <- kmeans(t, 2)
cl
plot(t, col = c("blue", "green")[cl$cluster])
legend("bottomright",legend=c("1","2"),fill=c("blue","green"))


n<-30
n.train<-floor(n*0.7)            #?????????????????? ??????????????
n.test<-n-n.train                #???????????????? ??????????????

idx.train<-sample(1:n, n.train)   #?????????????????? ?????????? ????????????????
idx.test<-setdiff(1:n, idx.train)

data.train<-xy[idx.train,]       #???????????????? ???????????? ???? ????????????????
data.test<-xy[idx.test,]


cl.cluster<-cl$cluster
cl.train<-cl.cluster[idx.train]
cl.test<-cl.cluster[idx.test]

mod<-qda(data.train, cl.train)               #???????????????? ???????????????? ??????????????
cl.test_est<-predict(mod, data.test)$class   #?????????????????????????? ?????????? ????????????
sum(cl.test_est!=cl.test)/n.test             #?????????????????? ????????????
idx.wrong<-idx.test[cl.test_est!=cl.test] 


plot(xy, type = "n", xlab = "x", ylab = "y") 
points(xy[idx.train,], pch = 2, col = c("blue", "green")[cl.train])
points(xy[idx.test,], col = c("blue", "green")[cl.test])
points(xy[idx.wrong, 1], xy[idx.wrong, 2], pch = 4, col = "red") 


n.wrong.new <-floor(n.train*0.2)

idx.train.new <- sample(1:n.train, n.wrong.new)
idx.real <- idx.train[idx.train.new]
cl.train.new <- cl.cluster[idx.train]
for(i in idx.train.new){
  if(cl.train.new[i] == 1)
    cl.train.new[i] = 2
  else
    cl.train.new[i] = 1
}


mod<-qda(data.train, cl.train.new)               
cl.test_est<-predict(mod, data.test)$class
sum(cl.test_est!=cl.test)/n.test             
idx.wrong<-idx.test[cl.test_est!=cl.test] 

plot(xy, type = "n", xlab = "x", ylab = "y") 
points(xy[idx.train,], pch = 0, col = c("blue", "green")[cl.train.new])
points(xy[idx.test,], pch = 18, col = c("blue", "green")[cl.test])
points(xy[idx.real,], pch = 4, col = "red") 
points(xy[idx.wrong, 1], xy[idx.wrong, 2], pch = 3, col = "black")